{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Data Cleaning module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_cleaning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code that replicates the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run paper_replication.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should see that the accuracy of the code is floating around 55%, which is just a little bit higher than a 50%/50% guess. This is possibly due to the small data size and the performance of GPT2 model. In the upcoming weeks, we will try larger dataset and more language models to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code that make Twitter predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714202143ba4f62a6276e9f8d97b720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc19b003a204f8d86e956619a2e6b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12/12 [==============================] - 2s 32ms/step - loss: 21992504.0000 - auc: 0.4591 - binary_accuracy: 0.5556 - val_loss: 11135.2129 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 15386988.0000 - auc: 0.4597 - binary_accuracy: 0.5889 - val_loss: 90879.1406 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 11996099.0000 - auc: 0.4243 - binary_accuracy: 0.5222 - val_loss: 287893.5000 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 7767732.0000 - auc: 0.4820 - binary_accuracy: 0.5556 - val_loss: 768352.3125 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 8259991.0000 - auc: 0.4712 - binary_accuracy: 0.5889 - val_loss: 864942.0000 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 6272495.0000 - auc: 0.5174 - binary_accuracy: 0.6222 - val_loss: 812786.5000 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5964940.5000 - auc: 0.3630 - binary_accuracy: 0.5000 - val_loss: 848073.1250 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5601304.0000 - auc: 0.4633 - binary_accuracy: 0.5778 - val_loss: 838232.8750 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 3662102.7500 - auc: 0.4483 - binary_accuracy: 0.5889 - val_loss: 752269.6250 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 5237849.5000 - auc: 0.4165 - binary_accuracy: 0.5111 - val_loss: 626917.8125 - val_auc: 0.5000 - val_binary_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 276ms/step\n",
      "Accuracy Score: 0.800\n"
     ]
    }
   ],
   "source": [
    "%run tweets_prediction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy score of our model varies in a huge range. This is largely because we rely on manually labeling for the validation data creation and the dataset is very small. We will test on larger datasets in upcoming weeks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
